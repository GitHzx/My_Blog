---
title: '半全局立体匹配法笔记'
date: 2021-03-04 14:54:51
tags: []
published: true
hideInList: false
feature: 
isTop: false
---

---
author:
- HFB


# 算法简介

&emsp;&emsp;2005年，德国航空航天中心(DLR)机器人和机电一体化研究所计算机视觉研究员Heiko Hirschmüller发表了文章《Stereo Processing by Semi-Global Matching and Mutual Information》，文章中提出了经典的Semi-Global Matching算法。截止目前，该文章在谷歌学术上显示被引次数已高达2536。

&emsp;&emsp;传统稠密立体匹配方法的基本思想来源于多视图几何：给定校正过后的极线水平的双目左右视图，假如能够找出每一个三维点在两幅图上对应像素对，就能通过像素对视差计算出三维点深度。

<img src="../../post-images/SGM/1.jpg" alt="The 1" width = "400" height = "300"/>

&emsp;&emsp;稠密立体匹配方法首先计算左视图像素与右视图上对应极线上待匹配像素的相似度，选择相似度最大的作为对应像素对，该最优化策略就是"winner-takes-all"。由于单个像素的匹配易受干扰影响，所以发展出了计算以目标像素附近整个windows区域内像素相关性的局部匹配方法。局部匹配代价的计算方法有很多种：灰度差平方和(SSD)，灰度差绝对值和(SAD)，归一化互相关(NCC)，Rank变换，Census变换等方法。为了进一步去除误匹配点，应用连续性约束、唯一性约束、顺序性约束等约束条件筛选出误匹配点并进行重匹配。

&emsp;&emsp;局部匹配法只考虑了局部信息，无法处理重复纹理区域及弱纹理，同时，在滑动窗口上的应用深度连续变化约束会使得深度值变化剧烈的边界被平滑。全局匹配方法就是为了解决以上问题而提出的。该方法依然计算两图像之间像素匹配的相似度：考虑一对尺寸为$m \cdot n$的图像对，视差范围为$d$，那么左视图上的每个点都要与右视图对应极线上$d$个像素匹配并计算相似度，或称匹配代价，最终的得到整个的匹配代价矩阵为$m \cdot n \cdot d$。"winner-takes-all"即是直接选取每个像素d轴上的最值，然而，局部最值不一定全局最优的。全局匹配法设计了一个含有附加约束的全局代价聚合函数，并假定当代价函数损失最小时得到的视差图是最优的。全局代价函数的定义域是$m \cdot n$个像素的所有可能匹配代价的组合集合，每个像素的匹配代价有$d$种情况，故集合一共有$d^{m \cdot n}$个组合。简短来说，全局匹配问题就是在三维的代价矩阵空间中找出一个代价曲面，该代价曲面使得全局代价聚合函数最小化。直接遍历全部$d^{m \cdot n}$个曲面显然是一个NP问题。

&emsp;&emsp;半全局立体匹配方法是对传统全局立体匹配方法的一种发展，降低了全局方法对时间的耗用，实现了匹配精度与速度的平衡。由于匹配代价矩阵对应的求解空间很大，全局匹配的最优视差求解属于NP-complete问题。半全局立体匹配通过在图像平面上应用多方向一维代价聚合来近似二维代价聚合，即在三维的代价矩阵空间中用多个方向上曲线表征整个曲面，大大降低了问题的时间复杂度，使之得以在多项式时间内求解。

# 算法详述

&emsp;&emsp;半局立体匹配的工作流程主要分为以下几个步骤：1.像素匹配代价计算2.代价聚合与最优视差求解3.视差图优化。

## 像素匹配代价计算

&emsp;&emsp;半全局匹配法的第一步是像素匹配代价计算。遍历左视图中的全部像素得到$m \cdot n \cdot d$的匹配代价矩阵，其计算的时间复杂度为$O(m\cdot n\cdot d)$。

### MI 代价

#### 香农熵与互信息

&emsp;&emsp;Heiko Hirschmüller在论文中使用了基于互信息(Mutual Information)的匹配代价计算方法，该方法对光照变化不敏感。互信息建立在熵的概念之上。

&emsp;&emsp;量化信息的基本想法是使用不确定性，事件发生即是随机变量取值，发生概率小的事件信息量大，发生概率大的事件信息量少，必然发生的事件没有信息量。故信息是不确定性的消除量。自信息(Self Information)由Claude Shannon提出，在事件发生前表征事件发生的不确定性，在事件发生后表征事件发生提供的信息量。随机变量$X$的某一特定取值$X=x$，即事件$x$的自信息由其概率$P(x)$定义：
$$
SI(x)=-\log{P(x)}
$$
&emsp;&emsp;自信息只能衡量随机变量某一值状态的信息量。香农熵$H$是随机变量的自信息的期望，表征了随机变量所有可能值的概率分布的期望信息总量，非均匀分布比均匀分布的熵要小：
$$
H(X)=\mathbb{E}_{x\sim P}[SI(x)]=-\sum_{x}{P(x)\log{P(x)}}
$$
&emsp;&emsp;当存在多个随机变量时，通过联合熵来衡量联合分布的信息量。随机变量独立，联合熵等于随机变量的熵的加和；随机变量不完全相关，联合熵大于单个随机变量的熵，小于随机变量熵的加和；随机变量完全相关同分布，联合熵等于单个随机变量的熵。在假设有两个随机变量$X_{1},X_{2}$，其联合分布为$P_{X_{1},X_{2}}$：
$$
H(X_{1},X_{2})
    =-\sum_{x_{1}}\sum_{x_{2}}{P_{X_{1},X_{2}}(x_{1},x_{2})\log{P_{X_{1},X_{2}}(x_{1},x_{2})}}
$$
&emsp;&emsp;随机变量$X_{1}$与$X_{2}$的互信息(MutualIn formation)用来表征在已知$X_{2}$后，$X_{1}$熵的减少量：
$$
\begin{aligned}
    MI_{I_{1}I_{2}}
    &=-\sum_{x_{1}}\sum_{x_{2}}{P_{X_{1},X_{2}}(x_{1},x_{2})
    \log{(\frac{P_{X_{1},X_{2}}(x_{1},x_{2})}{P_{X_{1}}(x_{1})P_{X_{2}}(x_{2})})}}
    \\
    &=H(X_{1})+H(X_{2})-H(X_{1},X_{2})
\end{aligned}
$$
&emsp;&emsp;显然，两个随机变量相关性越高，联合熵越小，互信息就越大；两个随机变量独立时，互信息为零，$X_{1}$的熵不受影响。

#### Parzen核无参估计

&emsp;&emsp;对于分布不确定的随机变量，可以通过样本去估计随机变量的分布。若分布已知，参数未知，进行参数估计；若分布未知，则进行无参估计，即非参数估计。无参估计方法有KNN最近邻法，Parzen核密度估计法等。

&emsp;&emsp;Parzen核密度估计法基本思想是这样的：假设对一个未知分布的随机变量进行多次采样，这些离散分布的样本反映了该随机变量分布的特点。对于随机变量的某个特定取值，距离这个取值最近的样本最能反映该处的概率大小情况。即，每个样本都对随机变量的分布做出贡献，对自己所在的位置贡献最大，离得越远，贡献越小。

&emsp;&emsp;Parzen核函数有很多种，常用的两种是均匀核和高斯核函数。均匀核规定了一个带宽，超出带宽的样本对带宽内的分布贡献为零。高斯核规定每个样本对概率分布的贡献根据距离大小呈正态分布,距离$u$需要归一化$u\in[0,1]$。高斯核是一个高斯函数：
$$
\begin{aligned}
    K(u)=\frac{1}{\sqrt{2\pi}} \exp{\frac{-||u||}{2}}
\end{aligned}
$$
&emsp;&emsp;考虑随机变量$X$及其$N$个样本${X_{1},X_{2},...,X_{n}}$，假设其概率函数为$p(x)$，则用高斯核去估计$p(x)$：
$$
\begin{aligned}
    p(x)
    &=\frac{1}{N}\sum^{N}_{i=1}{K(||x-X_{i}||)}
    \\
    &=\frac{1}{N}\sum^{N}_{i=1}{\frac{1}{\sqrt{2\pi}} \exp{\frac{-||x-X_{i}||}{2}}}
\end{aligned}
$$

#### 图像匹配互信息的构建

&emsp;&emsp;图像直方图可以用来描述图像所包含的信息。若将图像的像素强度(Pixel
Intensity)看做一个随机变量，灰度图其取值则为$[0,255]$，用图像直方图估计其概率分布，从而可以利用该随机变量构建出图像匹配互信息代价。

&emsp;&emsp;对于左右两幅视图而言，二者所包含的大部分信息都一样，如果通过正确的视差将右视图完美的变换至与左视图重合，则两个随机变量完全相关，二者所含信息完全一样，互信息最大。将互信息取反，构建互信息代价的目的就是通过不断地优化每个像素的视差来使互信息代价达到最小。

&emsp;&emsp;假设图像$I$有$N$个像素，每个像素pixel$p$的像素强度$i$都服从分布$P(i)$。对于给定的图像，每个像素都相当于一个样本，故样本容量为$N$。首先对像素强度进行归一化，然后使用高斯核$g_{\psi}(u)$在样本集上对$P(i)$进行Parzen无参估计。即计算每一个像素强度样本与当前像素强度值的距离，再带入高斯核求取贡献值，最后累加起来得到当前像素强度值对应的概率。

左视图像素强度概率函数： 
$$
\begin{aligned}
    P_{I_{1}}(i)=\frac{1}{N}\sum_{p}{g_{\psi}(i-I_{1}(p))}
\end{aligned}
$$
&emsp;&emsp;通过视差图像$I_{d}$变换后的右视图像素强度概率函数： 
$$
\begin{aligned}
    P_{I_{2},I_{d}}(i)=\frac{1}{N}\sum_{p}{g_{\psi}(i-I_{2}(p+I_{d}(p)))}
\end{aligned}
$$
&emsp;&emsp;左视图与变换后右视图的联合概率函数： 
$$
\begin{aligned}
    P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})
    =\frac{1}{N}\sum_{p}{g_{\psi}((i_{1},i_{2})-(I_{1}(p),I_{2}(p+I_{d}(p))))}
\end{aligned}
$$
&emsp;&emsp;这里是二维随机变量，该变量为左视图与变换后右视图对应像素的像素强度值对。对于灰度图像，可能的取值$(i_{1},i_{2})$的值域大小为$256\times256$。样本为给定的左视图与变换后右视图对应像素的像素强度值对。

&emsp;&emsp;得到图像像素强度的概率函数后，就可以计算给定左右图像全部取值事件的熵以及联合熵。

&emsp;&emsp;左视图图像的熵： 
$$
\begin{aligned}
    H_{I_{1}}=-\sum_{i}{P_{I_{1}}(i)\log{P_{I_{1}}(i)}}
\end{aligned}
$$
&emsp;&emsp;通过视差图像$I_{d}$变换后的右视图图像的熵： 
$$
\begin{aligned}
    H_{I_{2},I_{d}}=-\sum_{i}{P_{I_{2},I_{d}}(i)\log{P_{I_{2},I_{d}}(i)}}
\end{aligned}
$$
&emsp;&emsp;左视图与变换后右视图的联合熵： 
$$
\begin{aligned}
    H_{I_{1},I_{2},I_{d}}
    =-\sum_{i_{1}}\sum_{i_{2}}{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})\log{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})}}
\end{aligned}
$$
&emsp;&emsp;互信息MI的定义基于两幅图像的熵$H_{I_{1}}$、$H_{I_{2},I_{d}}$和联合熵$H_{I_{1},I_{2},I_{d}}$：
$$
MI_{I_{1},I_{2},I_{d}}=H_{I_{1}}+H_{I_{2},I_{d}}-H_{I_{1},I_{2},I_{d}}
$$

#### 图像匹配互信息的近似

&emsp;&emsp;匹配的基本方法是通过不断调整左视图每个像素上的视差来使互信息最大。在理想情况下，互信息最大时右视图可以通过视差图变换至与左视图完全一致。此时，最优视差图$I^{*}_{d}$:
$$
I^{*}_{d}=\mathop{\arg\max}_{I_{d}}MI(I_{d})
$$
&emsp;&emsp;实际上，可以对图像匹配互信息$MI_{I_{1},I_{2},I_{d}}$进行近似处理以降低计算量。首先，左视图在整个优化匹配过程中熵不变，故可以省略；其次，右视图的视差变换只是对其像素位置有影响，其熵在视差变换前后不变，也可以忽略。给定的两图像的联合熵为$P_{I_{1},I_{2},I_{d}}$的函数，可以通过泰勒展开的方法将联合熵函数用一阶项近似，保证精度的同时化简计算。

&emsp;&emsp;对$x\log{x}$在$x_{0}$出进行一阶泰勒近似： 
$$
\begin{aligned}
    x\log{x}&=x_{0}\log{x_{0}} + (1+\log{x_{0}})(x-x_{0}) + O((x-x_{0})^{2})
    \\
    &\approx x_{0}\log{x_{0}} + (1+\log{x_{0}})(x-x_{0})
    \\
    &=x-x_{0}+x\log{x_{0}}
\end{aligned}
$$
&emsp;&emsp;若对两图像的联合熵在$P_{I_{1},I_{2},I_{d_{0}}}$处近似，应用以上近似公式：
$$
\begin{aligned}
    H_{I_{1},I_{2},I_{d}}
    \approx &-\sum_{i_{1}}\sum_{i_{2}}{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})}
    \\
    &+\sum_{i_{1}}\sum_{i_{2}}{P_{I_{1},I_{2},I_{d_{0}}}(i_{1},i_{2})}
    \\
    &-\sum_{i_{1}}\sum_{i_{2}}{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})\log{P_{I_{1},I_{2},I_{d_{0}}}(i_{1},i_{2})}}
\end{aligned}
$$
&emsp;&emsp;显然，前两项无论在何种$I_{d}$上均为$1$，二者相减为$0$。则有：
$$
\begin{aligned}
    H_{I_{1},I_{2},I_{d}}
    \approx -\sum_{i_{1}}\sum_{i_{2}}{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})\log{P_{I_{1},I_{2},I_{d_{0}}}(i_{1},i_{2})}}
\end{aligned}
$$
&emsp;&emsp;这里需要解释一下能够近似的原因：当我们采用基于图像直方图定义的像素强度随机变量来描述图像时，图像内部像素之间的位置关系不会影响随机变量的分布，随机变量的分布取决于给定图像直方图分布。所以在双目图像匹配的过程中，无论是左图还是右图，其直方图不变，随机变量分布不变，熵不变。但是，由于不同的视差图会导致两幅图像像素的匹配关系不同，匹配的强度值的变化使得联合概率函数随之变化，故联合熵会随着双目图像匹配的过程而发生变化。如前所述，分布的均匀程度与熵成正比。在理想情况下，当两幅图完美匹配后，左右两图中互相匹配的像素的强度相等，联合概率函数完全分布在$i_{1}=i_{2}$这条直线上，此时熵最小，互信息最大。但是，由于现有的算法很容易在双目图像匹配的迭代过程中保证绝大多数像素对都正确匹配，即产生联合概率函数的大部分样本保持固定，因此联合概率函数的变化处于由初始视差匹配得到的联合概率函数的\"邻域"之中。最终，我们认为可以在初始视差联合概率函数处进行一阶泰勒展开来近似计算联合熵。

<img src="../../post-images/SGM/3.jpg" alt="The 3" width = "900" height = "300"/>

&emsp;&emsp;实际上，在提出使用互信息代价的论文《Visual Correspondence Using Energy Minimization and Mutual Information》中，作者采取了进一步的简化。该论文认为当图像分辨率大，像素点很多时，我们已经获得了足够多的样本，因此可以在计算$P_{I_{1},I_{2},I_{d}}$时令Parzen高斯核的方差$\psi$趋于0。即相当于省略掉Parzen高斯核估计，直接采用样本频次作为$P_{I_{1},I_{2},I_{d}}$：
$$
\begin{aligned}
    H_{I_{1},I_{2},I_{d}}
    &\approx -\sum_{i_{1}}\sum_{i_{2}}{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})\log{P_{I_{1},I_{2},I_{d_{0}}}(i_{1},i_{2})}}
    \\
    &\approx-\sum_{i_{1}}\sum_{i_{2}}{\log{P_{I_{1},I_{2},I_{d_{0}}}(i_{1},i_{2})}\frac{1}{N}\sum_{p}{g_{\psi_{\to0}}((i_{1},i_{2})-(I_{1}(p),I_{2}(p+I_{d}(p))))}}
    \\
    &=-\sum_{i_{1}}\sum_{i_{2}}{\log{P_{I_{1},I_{2},I_{d_{0}}}(i_{1},i_{2})}\frac{1}{N}\sum_{p}{T[(i_{1},i_{2})=(I_{1}(p),I_{2}(p+I_{d}(p)))]}}
    \\
    &=-\frac{1}{N}\sum_{p}{(\sum_{i_{1}}\sum_{i_{2}}{\log{P_{I_{1},I_{2},I_{d_{0}}}(i_{1},i_{2})}T[(i_{1},i_{2})=(I_{1}(p),I_{2}(p+I_{d}(p)))]})}
    \\
    &=-\frac{1}{N}\sum_{p}{\log{P_{I_{1},I_{2},I_{d_{0}}}(I_{1}(p),I_{2}(p+I_{d}(p)))}}
\end{aligned}
$$
&emsp;&emsp;其中，函数$T$当等式为真时返回$1$，否则返回$0$。

&emsp;&emsp;对比简化前的$H_{I_{1},I_{2},I_{d}}$，我们可以看到：简化前，对于每一次迭代深度图，首先需要遍历该深度图下的$N$个全部匹配像素点对计算联合概率函数，然后遍历$256\cdot 256$个所有可能的像素点对的取值计算该深度图下的联合熵；简化后，只需要遍历一遍起始深度图下的$N$个全部匹配像素点对计算联合概率函数，然后对于每一次迭代的深度图遍历$N$个全部匹配像素点计算该深度图下的联合熵。

#### 图像匹配互信息代价

&emsp;&emsp;互信息代价作为全局代价函数中的数据项，除了数据项以外还有平滑项。

&emsp;&emsp;在之前的互信息近似过程中，我们忽略了左右两幅图像本身的熵$H_{I_{1}}$和$H_{I_{2},I_{d}}$，但这只在无干扰的理想情况下成立。Heiko Hirschmüller指出，当图像某些区域因遮挡、镜面反射而无法作为样本反映直方图分布时，图像本身的熵也会因匹配关系而发生变化。错误的视差图会把无法匹配的遮挡区域作为样本，并在左右图之间建立错误的匹配关系，从而导致互信息变小。Heiko Hirschmüller建议不要省略左右图像的熵$H_{I_{1}}$和$H_{I_{2},I_{d}}$，概率函数采用联合概率函数的边缘分布：
$$
\begin{aligned}
    P_{I_{1}}(i_{1})&=\sum_{i_{2}}{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})}
\end{aligned}
$$
$$
\begin{aligned}
    P_{I_{2},I_{d}}(i_{2})&=\sum_{i_{1}}{P_{I_{1},I_{2},I_{d}}(i_{1},i_{2})}
\end{aligned}
$$
&emsp;&emsp;左右图像的熵也采用类似的近似方法计算： 
$$
\begin{aligned}
    H_{I_{1}}&=-\frac{1}{N}\sum_{p}{\log{P_{I_{1}}(I_{1}(p),I_{2}(p+I_{d}(p)))}}
\end{aligned}
$$

$$
\begin{aligned}
    H_{I_{2},I_{d}}&=-\frac{1}{N}\sum_{p}{\log{P_{I_{2},I_{d}}(I_{1}(p),I_{2}(p+I_{d}(p)))}}
\end{aligned}
$$
&emsp;&emsp;联合熵依然采用之前近似结果： 
$$
\begin{aligned}
    H_{I_{1},I_{2},I_{d}}
    =-\frac{1}{N}\sum_{p}{\log{P_{I_{1},I_{2},I_{d_{0}}}(I_{1}(p),I_{2}(p+I_{d}(p)))}}
\end{aligned}
$$
&emsp;&emsp;最后给出互信息代价的最终形式： 
$$
\begin{aligned}
    E_{data}^{MI}
    &=-MI_{I_{1},I_{2},I_{d}}
    \\
    &=-{(H_{I_{1}}+H_{I_{1},I_{d}}-H_{I_{1},I_{2},I_{d}})}
    \\
    &=\sum_{p}{-(h_{I_{1}}+h_{I_{1},I_{d}}-h_{I_{1},I_{2},I_{d}})}
    \\
    &=\sum_{p}{C_{MI}(p,I_{d}(p))}
\end{aligned}
$$

### Census 代价

待补

### BT 代价

待补

## 代价聚合与最优视差求解

&emsp;&emsp;互信息代价是逐像素$p$计算$C_{MI}(p,I_{d}(p))$的，尽管这能保证正确匹配的点具有相似的像素强度，但没有考虑像素点的位置关系，以及噪声点的影响。比如，无法避免两幅图中存在的相同噪声点的匹配。因此，全局代价函数除了包含基于像素的数据项以外，还需要引入平滑项约束同时注意边缘保持。

### 全局代价函数

&emsp;&emsp;Heiko Hirschmüller文章中的全局代价函数，又称能量函数定义如下：
$$
\begin{aligned}
    E(I_{p})
    =\sum_{p}(&C_{MI}(p,I_{d}(p))
    \\
    &+\sum_{k\in N_{p}}{\zeta_{1}\cdot T[|I_{d}(k)-I_{d}(p)|=1]} 
    \\
    &+\sum_{k\in N_{p}}{\zeta_{2}(I_{1}(k),I_{1}(p))\cdot T[|I_{d}(k)-I_{d}(p)|>1]})
\end{aligned}
$$
&emsp;&emsp;其中，$N_{p}$是以像素$p$为中心的局部窗口。函数$T$当等式为真时返回$1$，否则返回$0$。$\zeta_{1}$是常数；$\zeta_{2}(I_{1}(k),I_{1}(p))$是像素强度差$|I_{1}(k)-I_{1}(p)|$的函数，满足关系：$\zeta_{2}(I_{1}(k),I_{1}(p))=\frac{\zeta_{2}}{|I_{1}(k)-I_{1}(p)|}$。但必须始终保证$\zeta_{2}(I_{1}(k),I_{1}(p))>\zeta_{1}$。

&emsp;&emsp;全局代价函数是按照当前视差图所反映的匹配关系，逐个匹配像素对计算然后叠加的。对于每个左右匹配像素对来说：第一项称为数据项，代表该像素对的匹配代价，当该像素对像素强度不相似时，互信息代价变大；第二项是局部平滑项，在局部窗口$N_{p}$内按照视差局部连续性对视差进行检查，如果窗口内像素视差与中心像素$p$视差差值为$1$，则平滑项代价变大；第三项是边缘保持项，当局部窗口$N_{p}$内两个像素位于同一物体表面时，它们的像素强度相似，此时系数$\zeta_{2}(I_{1}(k),I_{1}(p))$较大，能够对两像素视差差值大于$1$的情况进行惩罚，当两个像素分布位于前后景时，它们的像素强度相异，系数$\zeta_{2}(I_{1}(k),I_{1}(p))$较小，从而保证两个像素的视差差值不被惩罚，前后景的边缘得到保持。这三项相互制约，第一项最优则会导致大量噪声点存在，第二项最优则第一项变大且边缘无法保持，第三项最优则第一项变大。

### 半全局最优求解法

&emsp;&emsp;全局代价函数的优化问题最简单的求解方式就是穷举法，对每个像素计算其所有可能的视差匹配代价，然后再按照全局代价函数聚合起来取其最值，时间复杂度很高。相比之下，可以使用动态规划在多项式时间内沿着单个图像行进行一维最优化，但这样存在的问题是列方向上无法进行平滑约束。

&emsp;&emsp;半全局优化方法在一维和二维之间做了折中，通过在多个一维方向上进行代价聚合以近似全图像上的二维代价聚合，在保证视差图质量的基础上大幅降了低计算量。论文中，Hirschmüller使用了$16$个方向作为示范。

<img src="../../post-images/SGM/16directions.png" alt="The 3" width = "400" height = "300"/>

&emsp;&emsp;记$r$为某一个方向，$L_{r}(p,I_{d}(p))$为沿该方向从起始像素点一直到像素点$p$的一维方向代价函数，$L_{r}(p,I_{d}(p))$使用递归方式进行的定义：
$$
\begin{aligned}
    L_{r}(p,I_{d}(p))
    \\
    =C_{MI}(p,&I_{d}(p)
    \\
    +\min(&L_{r}(p_{r}(-1),I_{d}(p))
    \\
    &L_{r}(p_{r}(-1),I_{d}(p)-1)+\zeta_{1},
    \\
    &L_{r}(p_{r}(-1),I_{d}(p)+1)+\zeta_{1},
    \\
    &\min_{i}(L_{r}(p_{r}(-1),I_{d}(p)+i))+\zeta_{2}(I_{1}(p_{r}(-1)),I_{1}(p)))
    \\
    -\min_{k}&(L_{r}(p_{r}(-1),I_{d}(p)+k))
\end{aligned}
$$
&emsp;&emsp;其中，$p_{r}(-1)$表示像素$p$沿$r$方向的前一个像素。

&emsp;&emsp;对于像素$p$处的方向代价，第一步是计算当前像素$p$的数据项代价；第二步沿同一方向上找到前一个像素$p_{r}(-1)$，递归地调用方向代价函数分别按照像素$p$的视差值、像素$p$的视差值$\pm1$、像素$p$的视差值$+i$（不超过视差范围）的四种视差值计算前一个像素$p_{r}(-1)$的方向代价值，取其最小值；第三步为了防止递归累加过大，减去前一个像素的方向代价累加最小值，从而得到上限约束$L_{r}\le C_{max}+\zeta_{2}$。第二步的四种代价值中，与$\zeta_{1}$相关的代价值代表局部平滑项，与$\zeta_{2}(I_{1}(p_{r}(-1)),I_{1}(p))$相关的代价值代表边缘保持项。虽然第二步只需要某个像素上四种代价值，但是其中边缘保持项的计算需要遍历该像素的所有差值大于$1$的视差并计算其代价，然后从中选择代价最小的作为边缘保持项。

<img src="../../post-images/SGM/the path.png" alt="The 3" width = "500" height = "300"/>

&emsp;&emsp;以上过程是递归执行的，递归终止条件是执行到该方向上的起始像素，每次递归计算方向代价都需要当前像素的数据项代价值及同方向上前一像素的四种方向代价值，递归结束后该方向上全部像素都参与了代价计算。于是，我们就可以得到该方向上某一路径的方向代价聚合值。

&emsp;&emsp;实际的计算过程：

&emsp;&emsp;1.首先计算该路径起始像素各个匹配视差下的代价$C_{MI}(p,I_{d}(p)$。

&emsp;&emsp;2.然后计算第二个像素各个匹配视差下的数据项代价$C_{MI}(p,I_{d}(p)$、第二个像素各个匹配视差下与前一像素视差差值为$\pm1$的平滑项代价、第二个像素各个匹配视差下与前一像素视差差值为$i$的边缘保持项代价。若视差范围为$d$，截止目前一共计算了$(d+d)$次数据项代价、$(d\cdot 2)$次局部平滑项代价、$(d\cdot  i)$次边缘保持项代价。然后按照聚合公式，在第二个像素$d$个视差下计算两个数据项代价和并加上前后两像素间局部平滑项和边缘保持项的最小值。最终得到第二个像素不同视差值下的$d$个方向聚合代价，并都减去最小的聚合代价值。

&emsp;&emsp;3.以第二个像素为起始像素，第二个像素不同视差值下的$d$个方向聚合代价替代第一步中的$C_{MI}(p,I_{d}(p)$，重复执行第二步2.直到最后一个像素。

&emsp;&emsp;我们可以看到，半全局优化方法对全局穷举法做了两处简化：第一，使用多方向一维聚合代价替代二维聚合代价。但这还不够，假设某方向上上的像素彼此之间都存在关联，那穷举该方向上像素的全部代价组合就是$d^{N_{r}}$。第二，将某方向上像素的关联性限定在局部区域，仅考虑某方向上两像素相邻之间的关联，计算两像素之间的局部平滑代价即边缘保持代价，然后叠加在一起。这样，整个的全局代价在多项式时间内就可以计算完毕。

<img src="../../post-images/SGM/8or16.png" alt="The 3" width = "400" height = "400"/>

&emsp;&emsp;某一像素点上的所有方向路径的数量必须至少为$8$，以便尽量拟合二维图像。在像素$p$的视差值$I_{d}(p)$上的全方向代价聚合函数为：
$$
\begin{aligned}
    S(p,I_{d}(p))=\sum_{r}{L_{r}(p,I_{d}(p))}
\end{aligned}
$$

### 视差图计算

&emsp;&emsp;对于每一个像素$d$，通过选择不同的优化$I_{d}(p)$找到使$S(p,I_{d}(p))$最小化的视差值$I^{*}_{d}(p)$：
$$
\begin{aligned}
    I^{*}_{d}(p)=\mathop{\arg\min}_{I_{d}(p)}{S(p,I_{d}(p))}
\end{aligned}
$$
&emsp;&emsp对于每一个像素$p$，执行以上最优化过程，从而得到整个视差图$I^{*}_{d}$。

## 视差图优化

&emsp;&emsp;产生的视差图像仍然可能包含某些错误。此外，通常存在需要恢复的无效区域。两者都可以通过视差图像的优化来处理。

### 视差图亚像素精细化

&emsp;&emsp;之前获得的视差值是离散的整数值，这样的视差值可能不是最优的，而且实际中物体的深度分布是连续的。对于亚像素估计，使用一个二次曲线基于邻近视差代价(即在该视差值附近的更高和更低的视差的代价)进行拟合，计算二次代价函数的最小代价值对应的视差。从理论上讲，使用二次曲线只是使用了视差的平方和进行简单的拟合，并不一定准确，然而由于计算简单，二次曲线拟合被用作一种近似计算。

### 视差图匹配一致性检查

&emsp;&emsp;对于左右图像的匹配像素对，其匹配关系具有一致对称性。对于左图像上某像素$p$，通过遍历右图像上对应极线上的像素可以找到匹配像素$q$，匹配代价为$S_{p\to q}$，深度图为$I_{dl}$；根据匹配的一致性，对于右图像上的像素$q$，通过遍历左图像上对应极线上的像素可以找到匹配像素$p$，匹配代价为$S_{q\to p}$，与$S_{p\to q}$相等，深度图为$I_{dr}$。然而，代价聚合步骤只对左图像进行了匹配，没有对左右图像进行对称匹配一致性检查。因此，如果从头计算并进行对称匹配一致性检查，可以检测出不符合对称匹配的点。

&emsp;&emsp;用一个小窗口的中值滤波器(即3×3)从$I_{dl}$和$I_{dr}$过滤异常匹配。$I_{dl}$和$I_{dr}$的计算通过执行一致性检查来确定遮挡和假匹配。每一个$I_{dl}$的视差与它对应的$I_{dr}$的视差进行比较，如果两者不同，视差将被设置为无效值($D_{inv}$)。

### 视差图异常点去除

&emsp;&emsp;视差图像可能包含异常值，即完全错误的视差，这是由于低纹理、反射、噪声等原因造成的。它们通常表现为小块的差异，这与周围的差异非常不同，也就是峰值，如图4所示。但是，小视差块也可以表示有效的深度结构。这可以通过预先定义小视差块的大小来区别有效小区域与无效峰值，过小的补丁不太可能代表有效的场景结构。

&emsp;&emsp;为了识别峰值区域，首先将视差图像进行网格分割。通过允许相邻视差在一个小区域内变化一个像素来进行网格分割，低于一定尺寸阈值的视差网格被认为为无效的。

### 无纹理区域处理

&emsp;&emsp;在室内环境中，前景经常出现在一个纹理弱的或没有纹理的背景前面，例如墙壁。能量函数$E(I_{p})$并没有考虑视差位置信息，因此，$E(I_{p})$无法准确地处理没有纹理的背景下的前景对象的视差。可以根据像素强度的梯度对代价中的局部平滑项进行调整，这有助于正确地计算在前景对象的视差。因为前景区域内部的像素强度梯度一致，并且与无纹理背景区域存在区别。

&emsp;&emsp;然而，SGM并不是在整个二维图像上应用能量函数，而是在所有方向的单个一维路径上计算能量函数，并将其求和。如果沿着一条1D路径遇到一个非纹理区域，只有在非纹理区域路径的前后两边存在纹理区域需要匹配时计算出的视差变化才可靠。但是，非纹理区域可能有不同的形状和大小，可能超出图像边界。当沿着一维的位置和方向路径计算时，可能在非纹理区域附近遇到同时具有纹理的前景和背景对象，在这种情况下，可以计算出正确的视差；也可能遇到有纹理的前景无纹理的背景，或无纹理的前景与有纹理的背景，或没有图像的非纹理区域，在这些情况下可能无法可靠地计算视差。所有这些情况下的路径相加很容易导致前景物体在无纹理背景前面出现模糊与不连续。

&emsp;&emsp;值得注意的是，这个问题是一种特殊情况，只适用于结构化环境中的某些场景。然而，对于提出一个解决方案来说，这似乎是非常重要的。首先，我们做了一些假设:

&emsp;&emsp;1\. 视差图像中的不连续不会发生在无纹理的区域内。

&emsp;&emsp;2\. 在同一物体表面上，作为非纹理区域也可能有一些可见纹理。

&emsp;&emsp;3\. 无纹理区域的表面可以近似为一个平面。

&emsp;&emsp;第一个假设基本上是正确的，因为深度不连续通常至少会在强度上引起一些视觉变化。否则，不连续就无法检测到。第二个假设是必要的，因为绝对无纹理背景表面的视差是无法确定的。第三个假设是最弱的，因为不同距离的非纹理表面通常以不同的强度出现，分段强度相等的区域可以看作是分段平面。

&emsp;&emsp;无纹理区域的识别是在像素强度图像$I$上通过固定的radiometric bandwidth值$\sigma_{r}$的MeanShift分割来完成的，大小为$P_{1}$，通常为$4$。因此，低于平滑惩罚阈值的像素强度变化被视为噪声。为了快速处理，spatial bandwidth值$\sigma_{s}$设置为一个较低的值(即5)。此外，所有小于某一阈值(即100像素)的片段都被忽略，因为较小的未纹理区域被SGM处理得很好。

&emsp;&emsp;基于假设2，只要非纹理表面包含一些纹理，非纹理区域的视差是模糊且不连续的，其中既含有不正确的前景视差，同时也包含正确的背景视差。因此，每个区域至少包含部分的正确视差。对于某一非纹理区域$A_{i}$，我们可以将对其分割成不同的视差子区域，然后对不同的视差值进行处理从而得到正确的视差。分割条件是允许一个分割区域内的邻近视差变化不超过一个像素，这种快速分割方法将非纹理区域分割成几个无纹理子区域$A_{ik}$。

&emsp;&emsp;基于假设1和3，无纹理区域视差值是连续的且可以近似成平面，所以具有不同视差值的几个子区域$A_{ik}$对应着不同的可能的平面$F_{ik}$。接下来，通过计算视差的最佳拟合平面来估计可能的物体表面深度。我们认为非常小的patch不太可能属于正确的平面，比如小于12个像素。然后，评估每个$A_{ik}$的视差值，将非纹理区域$A_{i}$的所有像素替换为假设平面$F_{ik}$的深度，并计算之前所有不属于假设平面的像素的代价$E_{ik}$。

&emsp;&emsp;对于匹配像素对$(p,q)$，如果其他具有更高视差的像素$p_{'}$也被映射到匹配图像中的同一像素$q$，则像素$p$被遮挡。具体来说，先将左右两幅图像进行匹配，对左图像像素$p$，得到右图像中对应极线上视差为$d$的匹配像素$q$；对右图像像素$q$进行匹配，得到左图像上对应匹配的像素$p_{'}$，如果像素$p_{'}$的视差$d^{'}>d$，则可以认为像素$p$被遮挡。

&emsp;&emsp;对于非纹理区域$A_{i}$上每一个像素强度一致的区域$A_{ik}$，选择成本$E_{ik}$最小时对应的拟合平面$F_{ik^{'}}$。为了使非纹理区域视差连续满足假设1，将不连续视差图的所有视差值替换为所选拟合平面$F_{ik^{'}}$对应的视差值：
$$
\begin{aligned}
    F_{i} &= F_{ik^{'}} 
    \\
    k^{'} &= \mathop{\arg\min}_{k}{E_{ik}}
\end{aligned}
$$
&emsp;&emsp;本文提出的方法与其他一些方法相似，使用了图像分割和平面拟合来优化初始视差图像。与其他方法不同的是，初始的视差图像由于SGM已经相当准确，所以只有在一定大小的非纹理区域需要修改，而不会对可能匹配良好的区域造成负面的影响。另一个区别是，优化视差的方法是基于视差图像中固有的少量假设，无需耗时的迭代。

### 视差边缘漏洞插值处理

&emsp;&emsp;之前的视差匹配一致性检查，异常值滤波可能会使一些视差无效，从而导致了视差图像上的漏洞，为了得到稠密的结果，需要对这些漏洞进行插值。

&emsp;&emsp;无效的视差分为遮挡和不匹配，两种情况的插值必须采用不同的执行方法。遮挡部分不能采用遮挡物的像素进行插值，而只能采用被遮挡物的像素进行插值，以避免不正确的插值。因此，将背景外推到遮挡区域是必要的。而不匹配造成的空洞可以基于周围相邻像素信息进行平滑的插值。

&emsp;&emsp;遮挡和不匹配的像素可以通过为左右匹配一致性检查被找出来。下图显示了的被遮挡像素$p_{1}$的匹配像素$q_{1}$所在的极线没有穿过match
image的视差函数。相比之下，不匹配像素$p_{2}$的匹配像素$q_{2}$所在的极线穿过了match
image的视差函数。因此，对于每一个无效的像素，通过检查其极线与视差函数是否存在交点，就可以将它标记为遮挡像素或不匹配像素。

![occlusion](https://githzx.github.io/My_Blog//post-images/SGM/occlusion.png){#fig:occlusion}

&emsp;&emsp;对于邻近遮挡像素的不匹配的像素也被视为遮挡像素，因为这些像素也要求必须从有效的背景像素外推。插值是根据有效的视差计算相邻的无效视差区域，这类似于SGM沿着八个方向的路径的方式。对于每个无效的像素，所有8个值$p_{i}\in N_{p}$都被存储，其中，$N_{p}$是像素$p$的邻域。最终的视差是：
$$
I_{d}(p) = 
\left\{
        \begin{array}{lr}
        seclow \ N_{p} \ \ &if\ p\ is\ occluded,
        \\
        med \ N_{p}        &if\ p\ is\ mismatched,
        \\
        I_{d}(p)                      &otherwise.
        \end{array}
\right.
$$
&emsp;&emsp;第一种情况下，通过选择次最低值second lowest确保利用视差值较低的背景信息对遮挡像素进行插入；第二种情况下，可以使用所有信息而不是局限于前景或背景，在不匹配的区域位于对象边界的情况下，使用中位数$med$代替平均值来保持不连续；第三种情况下，视差无需处理。

&emsp;&emsp;提出的插值方法具有独立于立体匹配方法的优点。唯一的要求是极线校正后的左右视差图像，用来区别遮挡和不匹配像素。最后，使用中值滤波可以用来去除剩余的不规则和过度平滑产生的视差值。

## 多视差图的正交融合

待补

# 结论

待补

# 参考文献
H. Hirschmuller, \"Stereo Processing by Semiglobal Matching and Mutual Information,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, no. 2, pp. 328-341, Feb. 2008, doi:10.1109/TPAMI.2007.1166.

Junhwan Kim, Kolmogorov and Zabih, \"Visual correspondence using energy minimization and mutual information,\" Proceedings Ninth IEEE International Conference on Computer Vision, Nice, France, 2003, pp. 1033-1040 vol.2, doi: 10.1109/ICCV.2003.1238463.